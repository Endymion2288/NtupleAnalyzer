# ==============================================================================
# jup_data.sub - HTCondor submit file for JUP Data analysis
# ==============================================================================
# Submit JUP data analysis jobs
#
# Usage:
#   condor_submit jup_data.sub                      # Submit with defaults
#   condor_submit jup_data.sub MAX_EVENTS=100000    # Limit events
# ==============================================================================

# Job configuration
universe = vanilla
executable = ./run_wrapper.sh

# Default parameters (can be overridden)
JOBS = 16
MAX_EVENTS = -1
JPSI_MUON_ID = soft
UPS_MUON_ID = tight

# Arguments passed to run_wrapper.sh
arguments = "run_jup_analysis.sh -j $(JOBS) -n $(MAX_EVENTS) --jpsi-muon-id $(JPSI_MUON_ID) --ups-muon-id $(UPS_MUON_ID)"

# Log files
log_dir = logs/jup_data
output = $(log_dir)/jup_data_$(Cluster)_$(Process).out
error = $(log_dir)/jup_data_$(Cluster)_$(Process).err
log = $(log_dir)/jup_data_$(Cluster)_$(Process).log

# Resource requests
request_memory = 64000
request_cpus = $(JOBS)
request_disk = 20G

# Job flavor (max runtime)
+JobFlavour = "workday"

# File transfer settings
should_transfer_files = YES
when_to_transfer_output = ON_EXIT
transfer_output_files = output

# Environment and proxy
getenv = True
use_x509userproxy = True
x509userproxy = /afs/cern.ch/user/x/xcheng/x509up_u180107

# Notification
notification = Error
notify_user = xcheng@cern.ch

# Requirements
requirements = (OpSysAndVer =?= "AlmaLinux9")

# Queue
queue
